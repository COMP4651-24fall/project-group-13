{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Extra Config as my pc has multiple JVMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Java Virtual Machines (8):\n",
      "    23 (arm64) \"Eclipse Adoptium\" - \"OpenJDK 23\" /Library/Java/JavaVirtualMachines/temurin-23.jdk/Contents/Home\n",
      "    19.0.2 (arm64) \"Amazon.com Inc.\" - \"Amazon Corretto 19\" /Users/him/Library/Java/JavaVirtualMachines/corretto-19.0.2/Contents/Home\n",
      "    17.0.8 (arm64) \"Oracle Corporation\" - \"Java SE 17.0.8\" /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home\n",
      "    11.0.23 (arm64) \"Amazon.com Inc.\" - \"Amazon Corretto 11\" /Users/him/Library/Java/JavaVirtualMachines/corretto-11.0.23/Contents/Home\n",
      "    11.0.22 (arm64) \"Eclipse Adoptium\" - \"OpenJDK 11.0.22\" /Library/Java/JavaVirtualMachines/temurin-11.jdk/Contents/Home\n",
      "    1.8.431.10 (x86_64) \"Oracle Corporation\" - \"Java\" /Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home\n",
      "    1.8.0_412 (arm64) \"Amazon\" - \"Amazon Corretto 8\" /Users/him/Library/Java/JavaVirtualMachines/corretto-1.8.0_412/Contents/Home\n",
      "    1.8.0_412 (x86_64) \"Amazon\" - \"Amazon Corretto 8\" /Users/him/Library/Java/JavaVirtualMachines/corretto-1.8.0_412-1/Contents/Home\n",
      "/Library/Java/JavaVirtualMachines/temurin-23.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "!/usr/libexec/java_home -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Java Home:  None\n",
      "Updated Java Home:  /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "java_path = \"/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home\"\n",
    "java_home = os.environ.get('JAVA_HOME', None)\n",
    "\n",
    "print(\"Existing Java Home: \",java_home)\n",
    "\n",
    "if (not java_home) or (java_path not in java_home):\n",
    "    os.environ['JAVA_HOME'] = java_path\n",
    "\n",
    "print(\"Updated Java Home: \",os.environ.get('JAVA_HOME', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java version \"17.0.8\" 2023-07-18 LTS\n",
      "Java(TM) SE Runtime Environment (build 17.0.8+9-LTS-211)\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 17.0.8+9-LTS-211, mixed mode, sharing)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print java version\n",
    "\n",
    "os.system('java -version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "train_df['Sex'] = train_df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\n",
    "train_df['Embarked'] = train_df['Embarked'].apply(lambda x: 0 if x == 'S' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/28 18:09:24 WARN Utils: Your hostname, Yuen-Man-Hims-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 10.89.166.58 instead (on interface en0)\n",
      "24/11/28 18:09:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/28 18:09:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"ensemble\")\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame(train_df)\n",
    "train, valid = data.randomSplit([0.5, 0.5], seed=12345)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols = train_df.columns[1:].to_list(),\n",
    "    outputCol = \"features\")\n",
    "train = assembler.transform(train)\n",
    "valid = assembler.transform(valid)\n",
    "y_true = valid.select('Survived').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Naive-bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/28 18:09:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/28 18:09:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(\n",
    "    smoothing=1.0, \n",
    "    modelType=\"complement\", \n",
    "    labelCol=\"Survived\"\n",
    "    )\n",
    "\n",
    "# train the model\n",
    "nbModel = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "nbResult = nbModel.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Sex|              Age|SibSp|Parch|   Fare|Embarked|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|  1|             19.0|    3|    2|  263.0|       0|[1.0,1.0,19.0,3.0...|[-102.90479354434...|[2.03711713726180...|       1.0|\n",
      "|       0|     1|  1|29.69911764705882|    0|    0|27.7208|       1|[1.0,1.0,29.69911...|[-0.1374212834842...|[0.87160295684474...|       0.0|\n",
      "|       0|     1|  1|             40.0|    0|    0|27.7208|       1|[1.0,1.0,40.0,0.0...|[-0.0021174196878...|[0.99788482046380...|       0.0|\n",
      "|       0|     1|  1|             42.0|    1|    0|   52.0|       0|[1.0,1.0,42.0,1.0...|[-2.7403122235727...|[0.06455018965571...|       1.0|\n",
      "|       0|     1|  1|             47.0|    0|    0|   52.0|       0|[1.0,1.0,47.0,0.0...|[-1.6284570623824...|[0.19623211457771...|       1.0|\n",
      "|       0|     1|  1|             71.0|    0|    0|34.6542|       1|[1.0,1.0,71.0,0.0...|[-1.2567258522722...|[0.99999987432742...|       0.0|\n",
      "|       0|     2|  0|             27.0|    1|    0|   21.0|       0|[2.0,0.0,27.0,1.0...|[-0.0196914219789...|[0.98050118774583...|       0.0|\n",
      "|       0|     2|  1|             32.0|    0|    0|   10.5|       0|[2.0,1.0,32.0,0.0...|[-1.4404177704818...|[0.99998559592603...|       0.0|\n",
      "|       0|     2|  1|             34.0|    1|    0|   26.0|       0|[2.0,1.0,34.0,1.0...|[-0.0024982465973...|[0.99750487142364...|       0.0|\n",
      "|       0|     2|  1|             35.0|    0|    0|   26.0|       0|[2.0,1.0,35.0,0.0...|[-0.0036634177815...|[0.99634328434666...|       0.0|\n",
      "|       0|     2|  1|             66.0|    0|    0|   10.5|       0|[2.0,1.0,66.0,0.0...|[-1.1993961379630...|[0.99999999998801...|       0.0|\n",
      "|       0|     3|  0|             16.0|    5|    2|   46.9|       0|[3.0,0.0,16.0,5.0...|[-8.2750976794738...|[2.54783172236805...|       1.0|\n",
      "|       0|     3|  0|             18.0|    1|    0|   17.8|       0|[3.0,0.0,18.0,1.0...|[-0.1047184761811...|[0.90057802106528...|       0.0|\n",
      "|       0|     3|  0|             18.0|    2|    0|   18.0|       0|[3.0,0.0,18.0,2.0...|[-0.0529731625040...|[0.94840546496854...|       0.0|\n",
      "|       0|     3|  0|             28.0|    0|    0| 7.8958|       0|(7,[0,2,5],[3.0,2...|[-5.2458214611306...|[0.99994754316129...|       0.0|\n",
      "|       0|     3|  0|             31.0|    1|    0|   18.0|       0|[3.0,0.0,31.0,1.0...|[-5.7041377089461...|[0.99942974888411...|       0.0|\n",
      "|       0|     3|  1|              4.0|    3|    2|   27.9|       0|[3.0,1.0,4.0,3.0,...|[-5.1295304927733...|[0.00591933899379...|       1.0|\n",
      "|       0|     3|  1|             19.0|    0|    0| 8.1583|       0|[3.0,1.0,19.0,0.0...|[-6.0391319852470...|[0.99939626912035...|       0.0|\n",
      "|       0|     3|  1|             20.0|    0|    0| 7.8542|       0|[3.0,1.0,20.0,0.0...|[-3.5033232150283...|[0.99964972903769...|       0.0|\n",
      "|       0|     3|  1|             21.0|    0|    0|    7.8|       0|[3.0,1.0,21.0,0.0...|[-2.2667344131122...|[0.99977335224717...|       0.0|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbResult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_y_pred = nbResult.select('prediction').toPandas().values\n",
    "nb_f1 = f1_score(y_true, nb_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Linear Support Vector Machine (LinearSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"Survived\", featuresCol=\"features\")\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(train)\n",
    "\n",
    "lsvcResult = lsvcModel.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Sex|              Age|SibSp|Parch|   Fare|Embarked|            features|       rawPrediction|prediction|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+----------+\n",
      "|       0|     1|  1|             19.0|    3|    2|  263.0|       0|[1.0,1.0,19.0,3.0...|[1.11859142297071...|       0.0|\n",
      "|       0|     1|  1|29.69911764705882|    0|    0|27.7208|       1|[1.0,1.0,29.69911...|[0.88578780970810...|       0.0|\n",
      "|       0|     1|  1|             40.0|    0|    0|27.7208|       1|[1.0,1.0,40.0,0.0...|[0.89721772738040...|       0.0|\n",
      "|       0|     1|  1|             42.0|    1|    0|   52.0|       0|[1.0,1.0,42.0,1.0...|[1.06649657993054...|       0.0|\n",
      "|       0|     1|  1|             47.0|    0|    0|   52.0|       0|[1.0,1.0,47.0,0.0...|[0.94127411707960...|       0.0|\n",
      "|       0|     1|  1|             71.0|    0|    0|34.6542|       1|[1.0,1.0,71.0,0.0...|[0.93161550377478...|       0.0|\n",
      "|       0|     2|  0|             27.0|    1|    0|   21.0|       0|[2.0,0.0,27.0,1.0...|[-0.8680139114384...|       1.0|\n",
      "|       0|     2|  1|             32.0|    0|    0|   10.5|       0|[2.0,1.0,32.0,0.0...|[0.99187559275310...|       0.0|\n",
      "|       0|     2|  1|             34.0|    1|    0|   26.0|       0|[2.0,1.0,34.0,1.0...|[1.12486529543503...|       0.0|\n",
      "|       0|     2|  1|             35.0|    0|    0|   26.0|       0|[2.0,1.0,35.0,0.0...|[0.99520440982353...|       0.0|\n",
      "|       0|     2|  1|             66.0|    0|    0|   10.5|       0|[2.0,1.0,66.0,0.0...|[1.02960218621791...|       0.0|\n",
      "|       0|     3|  0|             16.0|    5|    2|   46.9|       0|[3.0,0.0,16.0,5.0...|[-0.4738172564876...|       1.0|\n",
      "|       0|     3|  0|             18.0|    1|    0|   17.8|       0|[3.0,0.0,18.0,1.0...|[-0.8107548016241...|       1.0|\n",
      "|       0|     3|  0|             18.0|    2|    0|   18.0|       0|[3.0,0.0,18.0,2.0...|[-0.6799843103224...|       1.0|\n",
      "|       0|     3|  0|             28.0|    0|    0| 7.8958|       0|(7,[0,2,5],[3.0,2...|[-0.9304292360243...|       1.0|\n",
      "|       0|     3|  0|             31.0|    1|    0|   18.0|       0|[3.0,0.0,31.0,1.0...|[-0.7963299276522...|       1.0|\n",
      "|       0|     3|  1|              4.0|    3|    2|   27.9|       0|[3.0,1.0,4.0,3.0,...|[1.23643845966983...|       0.0|\n",
      "|       0|     3|  1|             19.0|    0|    0| 8.1583|       0|[3.0,1.0,19.0,0.0...|[1.04469627980688...|       0.0|\n",
      "|       0|     3|  1|             20.0|    0|    0| 7.8542|       0|[3.0,1.0,20.0,0.0...|[1.04580588549702...|       0.0|\n",
      "|       0|     3|  1|             21.0|    0|    0|    7.8|       0|[3.0,1.0,21.0,0.0...|[1.04691549118716...|       0.0|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsvcResult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_y_pred = lsvcResult.select('prediction').toPandas().values\n",
    "lsvc_f1 = f1_score(y_true, lsvc_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilayerPerceptronClassifier(\n",
    "    labelCol=\"Survived\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=1500, \n",
    "    layers=[7, 32, 64, 16, 2], \n",
    "    blockSize=64, \n",
    "    seed=1234\n",
    "    )\n",
    "\n",
    "# train the model\n",
    "mlpModel = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "mlpResult = mlpModel.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Sex|              Age|SibSp|Parch|   Fare|Embarked|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|  1|             19.0|    3|    2|  263.0|       0|[1.0,1.0,19.0,3.0...|[0.33219551564158...|[0.72767999677926...|       0.0|\n",
      "|       0|     1|  1|29.69911764705882|    0|    0|27.7208|       1|[1.0,1.0,29.69911...|[0.33219802082379...|[0.72768097704230...|       0.0|\n",
      "|       0|     1|  1|             40.0|    0|    0|27.7208|       1|[1.0,1.0,40.0,0.0...|[0.33219601623760...|[0.72768020779275...|       0.0|\n",
      "|       0|     1|  1|             42.0|    1|    0|   52.0|       0|[1.0,1.0,42.0,1.0...|[0.33222122790630...|[0.72768988259470...|       0.0|\n",
      "|       0|     1|  1|             47.0|    0|    0|   52.0|       0|[1.0,1.0,47.0,0.0...|[0.33219646966249...|[0.72768038179672...|       0.0|\n",
      "|       0|     1|  1|             71.0|    0|    0|34.6542|       1|[1.0,1.0,71.0,0.0...|[0.33219601246867...|[0.72768020635145...|       0.0|\n",
      "|       0|     2|  0|             27.0|    1|    0|   21.0|       0|[2.0,0.0,27.0,1.0...|[-1.0390408830984...|[0.15512383939633...|       1.0|\n",
      "|       0|     2|  1|             32.0|    0|    0|   10.5|       0|[2.0,1.0,32.0,0.0...|[0.44142682650593...|[0.76920620757611...|       0.0|\n",
      "|       0|     2|  1|             34.0|    1|    0|   26.0|       0|[2.0,1.0,34.0,1.0...|[0.34133864184622...|[0.73117448547091...|       0.0|\n",
      "|       0|     2|  1|             35.0|    0|    0|   26.0|       0|[2.0,1.0,35.0,0.0...|[0.33386424481002...|[0.72831991433727...|       0.0|\n",
      "|       0|     2|  1|             66.0|    0|    0|   10.5|       0|[2.0,1.0,66.0,0.0...|[5.75451955399352...|[0.99999417933342...|       0.0|\n",
      "|       0|     3|  0|             16.0|    5|    2|   46.9|       0|[3.0,0.0,16.0,5.0...|[0.33048085443585...|[0.72701596068453...|       0.0|\n",
      "|       0|     3|  0|             18.0|    1|    0|   17.8|       0|[3.0,0.0,18.0,1.0...|[0.08562315931847...|[0.62277849601470...|       0.0|\n",
      "|       0|     3|  0|             18.0|    2|    0|   18.0|       0|[3.0,0.0,18.0,2.0...|[0.26889871121462...|[0.70250818536573...|       0.0|\n",
      "|       0|     3|  0|             28.0|    0|    0| 7.8958|       0|(7,[0,2,5],[3.0,2...|[-0.1679801754177...|[0.50152605580571...|       0.0|\n",
      "|       0|     3|  0|             31.0|    1|    0|   18.0|       0|[3.0,0.0,31.0,1.0...|[0.15818477637964...|[0.65544548705785...|       0.0|\n",
      "|       0|     3|  1|              4.0|    3|    2|   27.9|       0|[3.0,1.0,4.0,3.0,...|[0.33190978786660...|[0.72755665578489...|       0.0|\n",
      "|       0|     3|  1|             19.0|    0|    0| 8.1583|       0|[3.0,1.0,19.0,0.0...|[10.9213015321491...|[0.99999999953503...|       0.0|\n",
      "|       0|     3|  1|             20.0|    0|    0| 7.8542|       0|[3.0,1.0,20.0,0.0...|[9.20783623583670...|[0.99999998716231...|       0.0|\n",
      "|       0|     3|  1|             21.0|    0|    0|    7.8|       0|[3.0,1.0,21.0,0.0...|[7.20260983622349...|[0.99999937636841...|       0.0|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlpResult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_y_pred = mlpResult.select('prediction').toPandas().values\n",
    "mlp_f1 = f1_score(y_true, mlp_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ensemble of 3 models (Naive-bayes, LinearSVM, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_total = nb_f1 + lsvc_f1 + mlp_f1\n",
    "y_pred = np.round((nb_y_pred * nb_f1 + lsvc_y_pred * lsvc_f1 + mlp_y_pred * mlp_f1)/f1_total)\n",
    "\n",
    "# Create accuracy score\n",
    "print(\"accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Create classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Produce the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test_df['Sex'] = train_df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "test_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\n",
    "test_df['Embarked'] = train_df['Embarked'].apply(lambda x: 0 if x == 'S' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = assembler.transform(spark.createDataFrame(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred = nbModel.transfor(test).select('prediction').toPandas().values\n",
    "lsvc_pred = lsvcModel.transfor(test).select('prediction').toPandas().values\n",
    "mlp_pred = mlpModel.transfor(test).select('prediction').toPandas().values\n",
    "\n",
    "y_pred = np.round((nb_pred * nb_f1 + lsvc_pred * lsvc_f1 + mlp_pred * mlp_f1)/f1_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../result/submission.csv', y_pred, delimiter=',', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
